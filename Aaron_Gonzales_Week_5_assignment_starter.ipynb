{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165166dd",
   "metadata": {},
   "source": [
    "# DS Automation Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195af74",
   "metadata": {},
   "source": [
    "Using our prepared churn data from week 2:\n",
    "- use pycaret to find an ML algorithm that performs best on the data\n",
    "    - Choose a metric you think is best to use for finding the best model; by default, it is accuracy but it could be AUC, precision, recall, etc. The week 3 FTE has some information on these different metrics.\n",
    "- save the model to disk\n",
    "- create a Python script/file/module with a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe\n",
    "    - your Python file/function should print out the predictions for new data (new_churn_data.csv)\n",
    "    - the true values for the new data are [1, 0, 0, 1, 0] if you're interested\n",
    "- test your Python module and function with the new data, new_churn_data.csv\n",
    "- write a short summary of the process and results at the end of this notebook\n",
    "- upload this Jupyter Notebook and Python file to a Github repository, and turn in a link to the repository in the week 5 assignment dropbox\n",
    "\n",
    "*Optional* challenges:\n",
    "- return the probability of churn for each new prediction, and the percentile where that prediction is in the distribution of probability predictions from the training dataset (e.g. a high probability of churn like 0.78 might be at the 90th percentile)\n",
    "- use other autoML packages, such as TPOT, H2O, MLBox, etc, and compare performance and features with pycaret\n",
    "- create a class in your Python module to hold the functions that you created\n",
    "- accept user input to specify a file using a tool such as Python's `input()` function, the `click` package for command-line arguments, or a GUI\n",
    "- Use the unmodified churn data (new_unmodified_churn_data.csv) in your Python script. This will require adding the same preprocessing steps from week 2 since this data is like the original unmodified dataset from week 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8aed9d-3fae-40d2-9a6a-683fa325810d",
   "metadata": {},
   "source": [
    "Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd75b65-10c1-4262-b8ee-2abfa58c5c0e",
   "metadata": {},
   "source": [
    "To begin, the prepped churn data is loaded into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "476ed965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>tenure_totalcharge_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7590-VHVEG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5575-GNVDE</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668-QPYBK</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795-CFOCW</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237-HQITU</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9305-CDSKC</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99.65</td>\n",
       "      <td>820.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452-KIOVK</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>89.10</td>\n",
       "      <td>1949.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713-OKOMC</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.75</td>\n",
       "      <td>301.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892-POOKP</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104.80</td>\n",
       "      <td>3046.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6388-TABGU</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>56.15</td>\n",
       "      <td>3487.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
       "customerID                                                                  \n",
       "7590-VHVEG       1             0         0              1           29.85   \n",
       "5575-GNVDE      34             1         1              0           56.95   \n",
       "3668-QPYBK       2             1         0              0           53.85   \n",
       "7795-CFOCW      45             0         1              2           42.30   \n",
       "9237-HQITU       2             1         0              1           70.70   \n",
       "9305-CDSKC       8             1         0              1           99.65   \n",
       "1452-KIOVK      22             1         0              3           89.10   \n",
       "6713-OKOMC      10             0         0              0           29.75   \n",
       "7892-POOKP      28             1         0              1          104.80   \n",
       "6388-TABGU      62             1         1              2           56.15   \n",
       "\n",
       "            TotalCharges  Churn  tenure_totalcharge_ratio  \n",
       "customerID                                                 \n",
       "7590-VHVEG         29.85      0                  0.033501  \n",
       "5575-GNVDE       1889.50      0                  0.017994  \n",
       "3668-QPYBK        108.15      1                  0.018493  \n",
       "7795-CFOCW       1840.75      0                  0.024447  \n",
       "9237-HQITU        151.65      1                  0.013188  \n",
       "9305-CDSKC        820.50      1                  0.009750  \n",
       "1452-KIOVK       1949.40      0                  0.011286  \n",
       "6713-OKOMC        301.90      0                  0.033124  \n",
       "7892-POOKP       3046.05      1                  0.009192  \n",
       "6388-TABGU       3487.95      0                  0.017775  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/aaron/Documents/Jupyter/data/prepped_churn_data.csv', index_col='customerID')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af95f6c-8d1a-4efb-b813-459be428660f",
   "metadata": {},
   "source": [
    "AutoML with Pycaret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b197c89-df66-4da2-95b0-5b32dad87adc",
   "metadata": {},
   "source": [
    "I am saving the cell below to be able to refer to this notebook later for reference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff4e680-123e-4954-91e5-68e2de799890",
   "metadata": {},
   "source": [
    "***FTE***\n",
    "\n",
    "Our next step is to use pycaret for autoML. \n",
    "\n",
    "PyCaret only supports up to Python 3.10 and I'm using Python 3.11, so I'm going to create a **virtual environment**. Instructions are at https://pycaret.gitbook.io/docs/get-started/installation.\n",
    "\n",
    "**NOTE:** I suggest doing all this from a command line, <u>not from inside your notebook</u>.\n",
    "\n",
    "```\n",
    "# create a conda environment\n",
    "conda create --name <yourenvname> anaconda python=3.10\n",
    "\n",
    "# activate conda environment\n",
    "conda activate <yourenvname>\n",
    "\n",
    "# install pycaret\n",
    "pip install pycaret\n",
    "\n",
    "# create notebook kernel\n",
    "python -m ipykernel install --user --name <yourenvname> --display-name \"<display-name-for yourenvname>\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5b76b-179e-4453-b844-2f25b6a80b72",
   "metadata": {},
   "source": [
    "The following allows checking the kernels available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1665caff-670b-4c04-aab4-3d782c10721b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Available kernels:\n",
      "  py310      /Users/aaron/Library/Jupyter/kernels/py310\n",
      "  python3    /Users/aaron/anaconda3/share/jupyter/kernels/python3\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3305f83d-e0a6-438f-b00b-a5a0d70ca4de",
   "metadata": {},
   "source": [
    "The new kernel is available and it has been selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a7a645-d575-42bb-9e29-7d67f4e19893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7032 entries, 7590-VHVEG to 3186-AJIEK\n",
      "Data columns (total 8 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   tenure                    7032 non-null   int64  \n",
      " 1   PhoneService              7032 non-null   int64  \n",
      " 2   Contract                  7032 non-null   int64  \n",
      " 3   PaymentMethod             7032 non-null   int64  \n",
      " 4   MonthlyCharges            7032 non-null   float64\n",
      " 5   TotalCharges              7032 non-null   float64\n",
      " 6   Churn                     7032 non-null   int64  \n",
      " 7   tenure_totalcharge_ratio  7032 non-null   float64\n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 494.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a93c28-bf1b-4b0f-a459-cacef8ea1006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycaret.classification import ClassificationExperiment #setup, compare_models, predict_model, save_model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e6650a-0fd8-4b0c-8a24-b8a6be7b9365",
   "metadata": {},
   "source": [
    "***Note for future reference, when looking back at this notebook.\n",
    "\n",
    "First install corrupted the whole environment, it was not known till after a system restart the next morning. Ananconda navigator would not start again. Fix was removing and installing navigator: \n",
    "\n",
    "conda remove -n base anaconda-navigator\n",
    "conda install -n base anaconda-navigator\n",
    "\n",
    "Next remove the new environment:\n",
    "\n",
    "conda deactivate\n",
    "conda remove --name ENV_NAME --all\n",
    "\n",
    "recreate environment per instructions above, it will fail on pycaret install. Issue is with lightgbm module install. Can't find library, it does not install it either\n",
    "\n",
    "Direct lightgbm install does't work either until you add additional channel:\n",
    "\n",
    "conda config --add channels conda-forge\n",
    "conda config --set channel_priority strict\n",
    "\n",
    "Reinstall lightgbm:\n",
    "\n",
    "conda install lightgbm\n",
    "\n",
    "Redo pycaret install, install still fails. Two dependencies are still needed, blosc2 and fuzzyTM. Install with:\n",
    "\n",
    "pip install fuzzytm\n",
    "pip install blosc2\n",
    "\n",
    "Rerun pycaret install. It finishes now. Finish step 4 from pycaret install above. Install complete. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd15b1-c139-444f-8632-af4f1e20bce6",
   "metadata": {},
   "source": [
    "Setting up for automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f40a7b-4caa-4b43-b967-55a168585fed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "automl = ClassificationExperiment() #setup(df, target='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8a2458-baa6-4df0-9e2c-3331691577eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ffdfd_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ffdfd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ffdfd_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_ffdfd_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ffdfd_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_ffdfd_row0_col1\" class=\"data row0 col1\" >4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ffdfd_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_ffdfd_row1_col1\" class=\"data row1 col1\" >Churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ffdfd_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_ffdfd_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ffdfd_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_ffdfd_row3_col1\" class=\"data row3 col1\" >(7032, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ffdfd_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_ffdfd_row4_col1\" class=\"data row4 col1\" >(7032, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ffdfd_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_ffdfd_row5_col1\" class=\"data row5 col1\" >(4922, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ffdfd_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_ffdfd_row6_col1\" class=\"data row6 col1\" >(2110, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ffdfd_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_ffdfd_row7_col1\" class=\"data row7 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ffdfd_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_ffdfd_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ffdfd_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_ffdfd_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ffdfd_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_ffdfd_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ffdfd_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_ffdfd_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ffdfd_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_ffdfd_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ffdfd_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_ffdfd_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ffdfd_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_ffdfd_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ffdfd_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_ffdfd_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ffdfd_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_ffdfd_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_ffdfd_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_ffdfd_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdfd_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_ffdfd_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_ffdfd_row18_col1\" class=\"data row18 col1\" >4660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b3bc8290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x2b17ed610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.setup(df, target='Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004db8a-dafe-4d11-bff3-65a1bb67a491",
   "metadata": {},
   "source": [
    "Automl is now setup\n",
    "\n",
    "***FTE***\n",
    "\n",
    "This will ask us to check if the datatypes of the input data are correct. In this case, they seem fine. There are a huge number of parameters we can set that we can see in the docs or if we run ?setup in a cell. For now, we are leaving everything else at the default. However, relating it to last week, we can see there is a feature_selection option we could set.\n",
    "\n",
    "By default, it preprocesses data (converts categorical columns into numeric). We can see what the preprocessed data looks like from one of the elements in the automl object. It seems like the index of the object (6 for unmodified data and 14 for preprocessed here) may change sometimes (possibly a bug or peculariaty with pycaret)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087f35f-fed9-4358-b277-15b0a7eb0862",
   "metadata": {},
   "source": [
    "Running automl to find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f89b3a-715c-4752-a3d2-b9c157254074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b43bb th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b43bb_row0_col0, #T_b43bb_row0_col3, #T_b43bb_row0_col5, #T_b43bb_row0_col6, #T_b43bb_row1_col0, #T_b43bb_row1_col1, #T_b43bb_row1_col2, #T_b43bb_row1_col3, #T_b43bb_row1_col4, #T_b43bb_row1_col5, #T_b43bb_row1_col6, #T_b43bb_row1_col7, #T_b43bb_row2_col0, #T_b43bb_row2_col1, #T_b43bb_row2_col2, #T_b43bb_row2_col3, #T_b43bb_row2_col4, #T_b43bb_row2_col5, #T_b43bb_row3_col0, #T_b43bb_row3_col1, #T_b43bb_row3_col2, #T_b43bb_row3_col3, #T_b43bb_row3_col4, #T_b43bb_row3_col5, #T_b43bb_row3_col6, #T_b43bb_row3_col7, #T_b43bb_row4_col0, #T_b43bb_row4_col1, #T_b43bb_row4_col2, #T_b43bb_row4_col3, #T_b43bb_row4_col4, #T_b43bb_row4_col5, #T_b43bb_row4_col6, #T_b43bb_row4_col7, #T_b43bb_row5_col0, #T_b43bb_row5_col1, #T_b43bb_row5_col2, #T_b43bb_row5_col3, #T_b43bb_row5_col4, #T_b43bb_row5_col5, #T_b43bb_row5_col6, #T_b43bb_row5_col7, #T_b43bb_row6_col0, #T_b43bb_row6_col1, #T_b43bb_row6_col2, #T_b43bb_row6_col3, #T_b43bb_row6_col4, #T_b43bb_row6_col5, #T_b43bb_row6_col6, #T_b43bb_row6_col7, #T_b43bb_row7_col0, #T_b43bb_row7_col1, #T_b43bb_row7_col2, #T_b43bb_row7_col3, #T_b43bb_row7_col4, #T_b43bb_row7_col5, #T_b43bb_row7_col6, #T_b43bb_row7_col7, #T_b43bb_row8_col0, #T_b43bb_row8_col1, #T_b43bb_row8_col2, #T_b43bb_row8_col3, #T_b43bb_row8_col4, #T_b43bb_row8_col5, #T_b43bb_row8_col6, #T_b43bb_row8_col7, #T_b43bb_row9_col0, #T_b43bb_row9_col1, #T_b43bb_row9_col2, #T_b43bb_row9_col3, #T_b43bb_row9_col4, #T_b43bb_row9_col6, #T_b43bb_row9_col7, #T_b43bb_row10_col0, #T_b43bb_row10_col1, #T_b43bb_row10_col2, #T_b43bb_row10_col3, #T_b43bb_row10_col4, #T_b43bb_row10_col5, #T_b43bb_row10_col6, #T_b43bb_row10_col7, #T_b43bb_row11_col0, #T_b43bb_row11_col1, #T_b43bb_row11_col2, #T_b43bb_row11_col3, #T_b43bb_row11_col4, #T_b43bb_row11_col5, #T_b43bb_row11_col6, #T_b43bb_row11_col7, #T_b43bb_row12_col0, #T_b43bb_row12_col1, #T_b43bb_row12_col2, #T_b43bb_row12_col4, #T_b43bb_row12_col5, #T_b43bb_row12_col6, #T_b43bb_row12_col7, #T_b43bb_row13_col0, #T_b43bb_row13_col1, #T_b43bb_row13_col2, #T_b43bb_row13_col3, #T_b43bb_row13_col4, #T_b43bb_row13_col5, #T_b43bb_row13_col6, #T_b43bb_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b43bb_row0_col1, #T_b43bb_row0_col2, #T_b43bb_row0_col4, #T_b43bb_row0_col7, #T_b43bb_row2_col6, #T_b43bb_row2_col7, #T_b43bb_row9_col5, #T_b43bb_row12_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_b43bb_row0_col8, #T_b43bb_row1_col8, #T_b43bb_row2_col8, #T_b43bb_row3_col8, #T_b43bb_row4_col8, #T_b43bb_row5_col8, #T_b43bb_row6_col8, #T_b43bb_row7_col8, #T_b43bb_row8_col8, #T_b43bb_row11_col8, #T_b43bb_row12_col8, #T_b43bb_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_b43bb_row9_col8, #T_b43bb_row10_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b43bb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b43bb_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_b43bb_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_b43bb_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_b43bb_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_b43bb_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_b43bb_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_b43bb_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_b43bb_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_b43bb_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row0\" class=\"row_heading level0 row0\" >gbc</th>\n",
       "      <td id=\"T_b43bb_row0_col0\" class=\"data row0 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_b43bb_row0_col1\" class=\"data row0 col1\" >0.7989</td>\n",
       "      <td id=\"T_b43bb_row0_col2\" class=\"data row0 col2\" >0.8392</td>\n",
       "      <td id=\"T_b43bb_row0_col3\" class=\"data row0 col3\" >0.4999</td>\n",
       "      <td id=\"T_b43bb_row0_col4\" class=\"data row0 col4\" >0.6602</td>\n",
       "      <td id=\"T_b43bb_row0_col5\" class=\"data row0 col5\" >0.5683</td>\n",
       "      <td id=\"T_b43bb_row0_col6\" class=\"data row0 col6\" >0.4406</td>\n",
       "      <td id=\"T_b43bb_row0_col7\" class=\"data row0 col7\" >0.4482</td>\n",
       "      <td id=\"T_b43bb_row0_col8\" class=\"data row0 col8\" >0.1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row1\" class=\"row_heading level0 row1\" >ada</th>\n",
       "      <td id=\"T_b43bb_row1_col0\" class=\"data row1 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_b43bb_row1_col1\" class=\"data row1 col1\" >0.7966</td>\n",
       "      <td id=\"T_b43bb_row1_col2\" class=\"data row1 col2\" >0.8362</td>\n",
       "      <td id=\"T_b43bb_row1_col3\" class=\"data row1 col3\" >0.5121</td>\n",
       "      <td id=\"T_b43bb_row1_col4\" class=\"data row1 col4\" >0.6488</td>\n",
       "      <td id=\"T_b43bb_row1_col5\" class=\"data row1 col5\" >0.5716</td>\n",
       "      <td id=\"T_b43bb_row1_col6\" class=\"data row1 col6\" >0.4409</td>\n",
       "      <td id=\"T_b43bb_row1_col7\" class=\"data row1 col7\" >0.4466</td>\n",
       "      <td id=\"T_b43bb_row1_col8\" class=\"data row1 col8\" >0.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row2\" class=\"row_heading level0 row2\" >lr</th>\n",
       "      <td id=\"T_b43bb_row2_col0\" class=\"data row2 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_b43bb_row2_col1\" class=\"data row2 col1\" >0.7956</td>\n",
       "      <td id=\"T_b43bb_row2_col2\" class=\"data row2 col2\" >0.8366</td>\n",
       "      <td id=\"T_b43bb_row2_col3\" class=\"data row2 col3\" >0.5260</td>\n",
       "      <td id=\"T_b43bb_row2_col4\" class=\"data row2 col4\" >0.6406</td>\n",
       "      <td id=\"T_b43bb_row2_col5\" class=\"data row2 col5\" >0.5772</td>\n",
       "      <td id=\"T_b43bb_row2_col6\" class=\"data row2 col6\" >0.4442</td>\n",
       "      <td id=\"T_b43bb_row2_col7\" class=\"data row2 col7\" >0.4482</td>\n",
       "      <td id=\"T_b43bb_row2_col8\" class=\"data row2 col8\" >0.2290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row3\" class=\"row_heading level0 row3\" >ridge</th>\n",
       "      <td id=\"T_b43bb_row3_col0\" class=\"data row3 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_b43bb_row3_col1\" class=\"data row3 col1\" >0.7936</td>\n",
       "      <td id=\"T_b43bb_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n",
       "      <td id=\"T_b43bb_row3_col3\" class=\"data row3 col3\" >0.4640</td>\n",
       "      <td id=\"T_b43bb_row3_col4\" class=\"data row3 col4\" >0.6594</td>\n",
       "      <td id=\"T_b43bb_row3_col5\" class=\"data row3 col5\" >0.5440</td>\n",
       "      <td id=\"T_b43bb_row3_col6\" class=\"data row3 col6\" >0.4159</td>\n",
       "      <td id=\"T_b43bb_row3_col7\" class=\"data row3 col7\" >0.4270</td>\n",
       "      <td id=\"T_b43bb_row3_col8\" class=\"data row3 col8\" >0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row4\" class=\"row_heading level0 row4\" >lightgbm</th>\n",
       "      <td id=\"T_b43bb_row4_col0\" class=\"data row4 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_b43bb_row4_col1\" class=\"data row4 col1\" >0.7930</td>\n",
       "      <td id=\"T_b43bb_row4_col2\" class=\"data row4 col2\" >0.8274</td>\n",
       "      <td id=\"T_b43bb_row4_col3\" class=\"data row4 col3\" >0.5206</td>\n",
       "      <td id=\"T_b43bb_row4_col4\" class=\"data row4 col4\" >0.6354</td>\n",
       "      <td id=\"T_b43bb_row4_col5\" class=\"data row4 col5\" >0.5718</td>\n",
       "      <td id=\"T_b43bb_row4_col6\" class=\"data row4 col6\" >0.4371</td>\n",
       "      <td id=\"T_b43bb_row4_col7\" class=\"data row4 col7\" >0.4412</td>\n",
       "      <td id=\"T_b43bb_row4_col8\" class=\"data row4 col8\" >1.1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row5\" class=\"row_heading level0 row5\" >lda</th>\n",
       "      <td id=\"T_b43bb_row5_col0\" class=\"data row5 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_b43bb_row5_col1\" class=\"data row5 col1\" >0.7899</td>\n",
       "      <td id=\"T_b43bb_row5_col2\" class=\"data row5 col2\" >0.8228</td>\n",
       "      <td id=\"T_b43bb_row5_col3\" class=\"data row5 col3\" >0.5046</td>\n",
       "      <td id=\"T_b43bb_row5_col4\" class=\"data row5 col4\" >0.6321</td>\n",
       "      <td id=\"T_b43bb_row5_col5\" class=\"data row5 col5\" >0.5604</td>\n",
       "      <td id=\"T_b43bb_row5_col6\" class=\"data row5 col6\" >0.4248</td>\n",
       "      <td id=\"T_b43bb_row5_col7\" class=\"data row5 col7\" >0.4299</td>\n",
       "      <td id=\"T_b43bb_row5_col8\" class=\"data row5 col8\" >0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row6\" class=\"row_heading level0 row6\" >rf</th>\n",
       "      <td id=\"T_b43bb_row6_col0\" class=\"data row6 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_b43bb_row6_col1\" class=\"data row6 col1\" >0.7714</td>\n",
       "      <td id=\"T_b43bb_row6_col2\" class=\"data row6 col2\" >0.8018</td>\n",
       "      <td id=\"T_b43bb_row6_col3\" class=\"data row6 col3\" >0.4648</td>\n",
       "      <td id=\"T_b43bb_row6_col4\" class=\"data row6 col4\" >0.5912</td>\n",
       "      <td id=\"T_b43bb_row6_col5\" class=\"data row6 col5\" >0.5188</td>\n",
       "      <td id=\"T_b43bb_row6_col6\" class=\"data row6 col6\" >0.3720</td>\n",
       "      <td id=\"T_b43bb_row6_col7\" class=\"data row6 col7\" >0.3776</td>\n",
       "      <td id=\"T_b43bb_row6_col8\" class=\"data row6 col8\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row7\" class=\"row_heading level0 row7\" >et</th>\n",
       "      <td id=\"T_b43bb_row7_col0\" class=\"data row7 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_b43bb_row7_col1\" class=\"data row7 col1\" >0.7702</td>\n",
       "      <td id=\"T_b43bb_row7_col2\" class=\"data row7 col2\" >0.7821</td>\n",
       "      <td id=\"T_b43bb_row7_col3\" class=\"data row7 col3\" >0.4893</td>\n",
       "      <td id=\"T_b43bb_row7_col4\" class=\"data row7 col4\" >0.5822</td>\n",
       "      <td id=\"T_b43bb_row7_col5\" class=\"data row7 col5\" >0.5305</td>\n",
       "      <td id=\"T_b43bb_row7_col6\" class=\"data row7 col6\" >0.3802</td>\n",
       "      <td id=\"T_b43bb_row7_col7\" class=\"data row7 col7\" >0.3834</td>\n",
       "      <td id=\"T_b43bb_row7_col8\" class=\"data row7 col8\" >0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row8\" class=\"row_heading level0 row8\" >knn</th>\n",
       "      <td id=\"T_b43bb_row8_col0\" class=\"data row8 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_b43bb_row8_col1\" class=\"data row8 col1\" >0.7668</td>\n",
       "      <td id=\"T_b43bb_row8_col2\" class=\"data row8 col2\" >0.7493</td>\n",
       "      <td id=\"T_b43bb_row8_col3\" class=\"data row8 col3\" >0.4426</td>\n",
       "      <td id=\"T_b43bb_row8_col4\" class=\"data row8 col4\" >0.5813</td>\n",
       "      <td id=\"T_b43bb_row8_col5\" class=\"data row8 col5\" >0.5017</td>\n",
       "      <td id=\"T_b43bb_row8_col6\" class=\"data row8 col6\" >0.3533</td>\n",
       "      <td id=\"T_b43bb_row8_col7\" class=\"data row8 col7\" >0.3593</td>\n",
       "      <td id=\"T_b43bb_row8_col8\" class=\"data row8 col8\" >0.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row9\" class=\"row_heading level0 row9\" >qda</th>\n",
       "      <td id=\"T_b43bb_row9_col0\" class=\"data row9 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_b43bb_row9_col1\" class=\"data row9 col1\" >0.7395</td>\n",
       "      <td id=\"T_b43bb_row9_col2\" class=\"data row9 col2\" >0.8227</td>\n",
       "      <td id=\"T_b43bb_row9_col3\" class=\"data row9 col3\" >0.7637</td>\n",
       "      <td id=\"T_b43bb_row9_col4\" class=\"data row9 col4\" >0.5078</td>\n",
       "      <td id=\"T_b43bb_row9_col5\" class=\"data row9 col5\" >0.6096</td>\n",
       "      <td id=\"T_b43bb_row9_col6\" class=\"data row9 col6\" >0.4262</td>\n",
       "      <td id=\"T_b43bb_row9_col7\" class=\"data row9 col7\" >0.4464</td>\n",
       "      <td id=\"T_b43bb_row9_col8\" class=\"data row9 col8\" >0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row10\" class=\"row_heading level0 row10\" >dummy</th>\n",
       "      <td id=\"T_b43bb_row10_col0\" class=\"data row10 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_b43bb_row10_col1\" class=\"data row10 col1\" >0.7343</td>\n",
       "      <td id=\"T_b43bb_row10_col2\" class=\"data row10 col2\" >0.5000</td>\n",
       "      <td id=\"T_b43bb_row10_col3\" class=\"data row10 col3\" >0.0000</td>\n",
       "      <td id=\"T_b43bb_row10_col4\" class=\"data row10 col4\" >0.0000</td>\n",
       "      <td id=\"T_b43bb_row10_col5\" class=\"data row10 col5\" >0.0000</td>\n",
       "      <td id=\"T_b43bb_row10_col6\" class=\"data row10 col6\" >0.0000</td>\n",
       "      <td id=\"T_b43bb_row10_col7\" class=\"data row10 col7\" >0.0000</td>\n",
       "      <td id=\"T_b43bb_row10_col8\" class=\"data row10 col8\" >0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row11\" class=\"row_heading level0 row11\" >dt</th>\n",
       "      <td id=\"T_b43bb_row11_col0\" class=\"data row11 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_b43bb_row11_col1\" class=\"data row11 col1\" >0.7298</td>\n",
       "      <td id=\"T_b43bb_row11_col2\" class=\"data row11 col2\" >0.6611</td>\n",
       "      <td id=\"T_b43bb_row11_col3\" class=\"data row11 col3\" >0.5015</td>\n",
       "      <td id=\"T_b43bb_row11_col4\" class=\"data row11 col4\" >0.4930</td>\n",
       "      <td id=\"T_b43bb_row11_col5\" class=\"data row11 col5\" >0.4964</td>\n",
       "      <td id=\"T_b43bb_row11_col6\" class=\"data row11 col6\" >0.3120</td>\n",
       "      <td id=\"T_b43bb_row11_col7\" class=\"data row11 col7\" >0.3125</td>\n",
       "      <td id=\"T_b43bb_row11_col8\" class=\"data row11 col8\" >0.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row12\" class=\"row_heading level0 row12\" >nb</th>\n",
       "      <td id=\"T_b43bb_row12_col0\" class=\"data row12 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_b43bb_row12_col1\" class=\"data row12 col1\" >0.7129</td>\n",
       "      <td id=\"T_b43bb_row12_col2\" class=\"data row12 col2\" >0.8110</td>\n",
       "      <td id=\"T_b43bb_row12_col3\" class=\"data row12 col3\" >0.7721</td>\n",
       "      <td id=\"T_b43bb_row12_col4\" class=\"data row12 col4\" >0.4753</td>\n",
       "      <td id=\"T_b43bb_row12_col5\" class=\"data row12 col5\" >0.5881</td>\n",
       "      <td id=\"T_b43bb_row12_col6\" class=\"data row12 col6\" >0.3864</td>\n",
       "      <td id=\"T_b43bb_row12_col7\" class=\"data row12 col7\" >0.4137</td>\n",
       "      <td id=\"T_b43bb_row12_col8\" class=\"data row12 col8\" >0.1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b43bb_level0_row13\" class=\"row_heading level0 row13\" >svm</th>\n",
       "      <td id=\"T_b43bb_row13_col0\" class=\"data row13 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_b43bb_row13_col1\" class=\"data row13 col1\" >0.6962</td>\n",
       "      <td id=\"T_b43bb_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n",
       "      <td id=\"T_b43bb_row13_col3\" class=\"data row13 col3\" >0.4740</td>\n",
       "      <td id=\"T_b43bb_row13_col4\" class=\"data row13 col4\" >0.5868</td>\n",
       "      <td id=\"T_b43bb_row13_col5\" class=\"data row13 col5\" >0.4428</td>\n",
       "      <td id=\"T_b43bb_row13_col6\" class=\"data row13 col6\" >0.2727</td>\n",
       "      <td id=\"T_b43bb_row13_col7\" class=\"data row13 col7\" >0.3204</td>\n",
       "      <td id=\"T_b43bb_row13_col8\" class=\"data row13 col8\" >0.1430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b6b24e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = automl.compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4032ecb-b927-4219-a25b-06d2af8c9a4e",
   "metadata": {},
   "source": [
    "With a quick glance, logical regression appears to be the best model in this scenario. My metric choice would be accuracy, that is what we have been working with the week or so and I read somewhere that accuracy is the default.\n",
    "\n",
    "The best model is now GBC after a kernel restart.\n",
    "\n",
    "\n",
    "***FTE***\n",
    "\n",
    "Within the notebook, this updates in real time as it's fitting. We can see the boosting algorithms like xgboost and catboost take the longest to run. Often xgboost will be near the top. To get xgboost and lightgbm working, we either need to allow preprocessing (which converts categorical columns into numeric columns) or we need to set our categorical columns as numeric with automl = setup(df, target='Diabetes', preprocess=False, numeric_features=['Gender']).\n",
    "\n",
    "Our best_model object now holds the highest-scoring model. We can also set an argument sort in compare_models to choose another metric as our scoring metric. By default, it uses accuracy (and we can see the table above is sorted by accuracy). We could set this to sort='Precision' to use precision (TP / (TP + FN)), for example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b709bc-dee6-45e5-8f3d-324988e92a9e",
   "metadata": {},
   "source": [
    "Find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a63bb8-f648-4c8b-8217-21447c44132b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(ccp_alpha=0.0, criterion=&#x27;friedman_mse&#x27;, init=None,\n",
       "                           learning_rate=0.1, loss=&#x27;log_loss&#x27;, max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                           n_estimators=100, n_iter_no_change=None,\n",
       "                           random_state=4680, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(ccp_alpha=0.0, criterion=&#x27;friedman_mse&#x27;, init=None,\n",
       "                           learning_rate=0.1, loss=&#x27;log_loss&#x27;, max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                           n_estimators=100, n_iter_no_change=None,\n",
       "                           random_state=4680, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='log_loss', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                           n_estimators=100, n_iter_no_change=None,\n",
       "                           random_state=4680, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9953053-c07d-4f65-a3bb-81641ff0e5e5",
   "metadata": {},
   "source": [
    "AutoML Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c27cbc32-6ac8-421e-bcd7-7deb63d98e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c1b5b1dde543edab50803ba8a44d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "automl.evaluate_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f45622-9661-4cd5-ac6e-b547d1a1e966",
   "metadata": {},
   "source": [
    "The best model was Logistic Regression, now it is GBC. \n",
    "\n",
    "\n",
    "\n",
    "Plotting and Predictions\n",
    "\n",
    "This is not part of the instructions for this assignment instructions, but a good thing to be exposed to. Following FTE examples. \n",
    "\n",
    "I have since pulled those additional FTE plots and predictions out for brevity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c308aa6-8954-499a-8f33-a810af9a8a3f",
   "metadata": {},
   "source": [
    "Save the model to disk\n",
    "\n",
    "\n",
    "save the model using pycaret to use again later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3192c999-d536-4c6a-a68b-de8704dac684",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['tenure', 'PhoneService',\n",
       "                                              'Contract', 'PaymentMethod',\n",
       "                                              'MonthlyCharges', 'TotalCharges',\n",
       "                                              'tenure_totalcharge_ratio'],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               fill_value=None,\n",
       "                                                               keep_empty_features=False,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='mean'...\n",
       "                                             criterion='friedman_mse', init=None,\n",
       "                                             learning_rate=0.1, loss='log_loss',\n",
       "                                             max_depth=3, max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100,\n",
       "                                             n_iter_no_change=None,\n",
       "                                             random_state=4680, subsample=1.0,\n",
       "                                             tol=0.0001, validation_fraction=0.1,\n",
       "                                             verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'pycaret_model.pkl')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.save_model(best_model, 'pycaret_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733b7cd-238d-466e-86ad-1a09de4e7945",
   "metadata": {},
   "source": [
    "The model is saved, now it is time to load it and test it making predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d75dd433-b500-44f0-816f-34a6093778ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "new_pycaret = ClassificationExperiment()\n",
    "loaded_model = new_pycaret.load_model('pycaret_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3851e4d5-9941-4d65-8c6b-34b23f34ddff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>tenure_totalcharge_ratio</th>\n",
       "      <th>Churn</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8361-LTMKD</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.400002</td>\n",
       "      <td>306.600006</td>\n",
       "      <td>0.013046</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
       "customerID                                                                  \n",
       "8361-LTMKD       4             1         0              0       74.400002   \n",
       "\n",
       "            TotalCharges  tenure_totalcharge_ratio  Churn  prediction_label  \\\n",
       "customerID                                                                    \n",
       "8361-LTMKD    306.600006                  0.013046      1                 1   \n",
       "\n",
       "            prediction_score  \n",
       "customerID                    \n",
       "8361-LTMKD             0.573  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pycaret.predict_model(loaded_model, df.iloc[-2:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99585cb9-34b2-41a0-97a7-514869bcc19f",
   "metadata": {},
   "source": [
    "The save model was successfully loaded and it was good to see it make a prediction. Successful or not, it was good to see it make a prediction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee792f-d6b9-440b-974a-2d77e768cee6",
   "metadata": {},
   "source": [
    "Create a Python script/file/module with a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe.\n",
    "\n",
    "This is to be done against the new_churn_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4951c9f3-fab4-43bc-ab28-4b11e00df256",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">pycaret.classification</span> <span class=\"kn\">import</span> <span class=\"n\">ClassificationExperiment</span>\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">load_data</span><span class=\"p\">(</span><span class=\"n\">filepath</span><span class=\"p\">):</span>\n",
       "<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<span class=\"sd\">    Loads diabetes data into a DataFrame from a string filepath.</span>\n",
       "<span class=\"sd\">    &quot;&quot;&quot;</span>\n",
       "    <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;/Users/aaron/Documents/Jupyter/data/prepped_churn_data.csv&#39;</span><span class=\"p\">,</span> <span class=\"n\">index_col</span><span class=\"o\">=</span><span class=\"s1\">&#39;customerID&#39;</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">df</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">make_predictions</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">):</span>\n",
       "<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<span class=\"sd\">    Uses the pycaret best model to make predictions on data in the df dataframe.</span>\n",
       "<span class=\"sd\">    &quot;&quot;&quot;</span>\n",
       "    <span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">ClassificationExperiment</span><span class=\"p\">()</span>\n",
       "    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">classifier</span><span class=\"o\">.</span><span class=\"n\">load_model</span><span class=\"p\">(</span><span class=\"s1\">&#39;pycaret_model&#39;</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">predictions</span> <span class=\"o\">=</span> <span class=\"n\">classifier</span><span class=\"o\">.</span><span class=\"n\">predict_model</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"o\">=</span><span class=\"n\">df</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">predictions</span><span class=\"o\">.</span><span class=\"n\">rename</span><span class=\"p\">({</span><span class=\"s1\">&#39;Label&#39;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;Churn&#39;</span><span class=\"p\">},</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">predictions</span><span class=\"p\">[</span><span class=\"s1\">&#39;Churn&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">({</span><span class=\"mi\">1</span><span class=\"p\">:</span> <span class=\"s1\">&#39;Churn&#39;</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">:</span> <span class=\"s1\">&#39;No churn&#39;</span><span class=\"p\">},</span>\n",
       "                                            <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">predictions</span><span class=\"p\">[</span><span class=\"s1\">&#39;Churn&#39;</span><span class=\"p\">]</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">load_data</span><span class=\"p\">(</span><span class=\"s1\">&#39;/Users/aaron/Documents/Jupyter/data/prepped_churn_data.csv&#39;</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">predictions</span> <span class=\"o\">=</span> <span class=\"n\">make_predictions</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n",
       "    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;predictions:&#39;</span><span class=\"p\">)</span>\n",
       "    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">predictions</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{pycaret}\\PY{n+nn}{.}\\PY{n+nn}{classification} \\PY{k+kn}{import} \\PY{n}{ClassificationExperiment}\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{load\\PYZus{}data}\\PY{p}{(}\\PY{n}{filepath}\\PY{p}{)}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\\PY{l+s+sd}{    Loads diabetes data into a DataFrame from a string filepath.}\n",
       "\\PY{l+s+sd}{    \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "    \\PY{n}{df} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{/Users/aaron/Documents/Jupyter/data/prepped\\PYZus{}churn\\PYZus{}data.csv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{index\\PYZus{}col}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{customerID}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{df}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{make\\PYZus{}predictions}\\PY{p}{(}\\PY{n}{df}\\PY{p}{)}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\\PY{l+s+sd}{    Uses the pycaret best model to make predictions on data in the df dataframe.}\n",
       "\\PY{l+s+sd}{    \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "    \\PY{n}{classifier} \\PY{o}{=} \\PY{n}{ClassificationExperiment}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{n}{model} \\PY{o}{=} \\PY{n}{classifier}\\PY{o}{.}\\PY{n}{load\\PYZus{}model}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{pycaret\\PYZus{}model}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "    \\PY{n}{predictions} \\PY{o}{=} \\PY{n}{classifier}\\PY{o}{.}\\PY{n}{predict\\PYZus{}model}\\PY{p}{(}\\PY{n}{model}\\PY{p}{,} \\PY{n}{data}\\PY{o}{=}\\PY{n}{df}\\PY{p}{)}\n",
       "    \\PY{n}{predictions}\\PY{o}{.}\\PY{n}{rename}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Label}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Churn}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{n}{inplace}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "    \\PY{n}{predictions}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Churn}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{replace}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+m+mi}{1}\\PY{p}{:} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Churn}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+m+mi}{0}\\PY{p}{:} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{No churn}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{,}\n",
       "                                            \\PY{n}{inplace}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{predictions}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Churn}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\n",
       "\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{n}{df} \\PY{o}{=} \\PY{n}{load\\PYZus{}data}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{/Users/aaron/Documents/Jupyter/data/prepped\\PYZus{}churn\\PYZus{}data.csv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "    \\PY{n}{predictions} \\PY{o}{=} \\PY{n}{make\\PYZus{}predictions}\\PY{p}{(}\\PY{n}{df}\\PY{p}{)}\n",
       "    \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{predictions:}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "    \\PY{n+nb}{print}\\PY{p}{(}\\PY{n}{predictions}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import pandas as pd\n",
       "from pycaret.classification import ClassificationExperiment\n",
       "\n",
       "def load_data(filepath):\n",
       "    \"\"\"\n",
       "    Loads diabetes data into a DataFrame from a string filepath.\n",
       "    \"\"\"\n",
       "    df = pd.read_csv('/Users/aaron/Documents/Jupyter/data/prepped_churn_data.csv', index_col='customerID')\n",
       "    return df\n",
       "\n",
       "\n",
       "def make_predictions(df):\n",
       "    \"\"\"\n",
       "    Uses the pycaret best model to make predictions on data in the df dataframe.\n",
       "    \"\"\"\n",
       "    classifier = ClassificationExperiment()\n",
       "    model = classifier.load_model('pycaret_model')\n",
       "    predictions = classifier.predict_model(model, data=df)\n",
       "    predictions.rename({'Label': 'Churn'}, axis=1, inplace=True)\n",
       "    predictions['Churn'].replace({1: 'Churn', 0: 'No churn'},\n",
       "                                            inplace=True)\n",
       "    return predictions['Churn']\n",
       "\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    df = load_data('/Users/aaron/Documents/Jupyter/data/prepped_churn_data.csv')\n",
       "    predictions = make_predictions(df)\n",
       "    print('predictions:')\n",
       "    print(predictions)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Code\n",
    "\n",
    "Code('predict_churn_pycaret.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a771acf9-6618-4118-b030-d99c541a0d61",
   "metadata": {},
   "source": [
    "The new predict file is loaded and ready to go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09b2350b-5fa9-462a-8b6a-21a207ad84e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n",
      "predictions:\n",
      "customerID\n",
      "7590-VHVEG    No churn\n",
      "5575-GNVDE    No churn\n",
      "3668-QPYBK       Churn\n",
      "7795-CFOCW    No churn\n",
      "9237-HQITU       Churn\n",
      "                ...   \n",
      "6840-RESVB    No churn\n",
      "2234-XADUH    No churn\n",
      "4801-JZAZL    No churn\n",
      "8361-LTMKD       Churn\n",
      "3186-AJIEK    No churn\n",
      "Name: Churn, Length: 7032, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x550 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run predict_churn_pycaret.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecb06a-ae2f-4dec-81d4-f95a0cc44dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c49db562",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533a1cd",
   "metadata": {},
   "source": [
    "This homework assignment was very interesting to say the least. It got off to a rocky start and then the whole environment died the next morning as was described in a cell above. After fixing that, things seemed to be going ok until the script portion. \n",
    "\n",
    "Going through the assignment, it was observered that the model can make predictions (both good and bad) and actually give that prediction in the prediction_label column and supplement that with the prediction_score that the prediction was based upon. That is the way how I thought the script was to work as well but that is not the case. \n",
    "\n",
    "Another observation that I made is that this model is wholy dependent on the specified target column in the beginning, that makes sense. So building the model based on a churn column and saving it to run against the new 5 entry new_churn_data.csv doesn't work because of target issues with not having the churn column in the new dataset. This results in the Key errors just like a mysql/sql script. That makes sense. \n",
    "\n",
    "The next step was starting with the original raw churn data csv. This is what I started with before everything died. Choosing this one gives the correct target column, but trying to run the script on the prepped churn still fails to run even though there are no key errors. I suspect this is because the pycaret_model that is called in the script will only work with the original dataset. I tried this with two different evironments and the same results were observed. This only works if the input dataset for the model and script are same/same. \n",
    "\n",
    "Is this expected behaviour or this an error that could be attributed to environment failure I had at the beginning? If this indeed expected bahaviour, which I am beginning to think it is, then that would make the script to be less generalised than expected because it completely dependent to the pycaret model and that only works in one scenario.\n",
    "\n",
    "Overall for this exercise, It was good to see predictions happen in the model. I got to learn how to do some of them and I feel I learned a decent amount on the dependencies both in and outside of the notebook in this scenario. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
